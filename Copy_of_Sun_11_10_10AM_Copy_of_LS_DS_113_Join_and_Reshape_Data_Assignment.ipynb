{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of  Sun 11/10 - 10AM Copy of LS_DS_113_Join_and_Reshape_Data_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LambdaTheda/DS-Unit-1-Sprint-1-Data-Wrangling-and-Storytelling/blob/master/Copy_of_Sun_11_10_10AM_Copy_of_LS_DS_113_Join_and_Reshape_Data_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pmU5YUal1eTZ"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 1, Sprint 1, Module 3*\n",
        "\n",
        "---\n",
        "\n",
        "# Join and Reshape datasets\n",
        "\n",
        "Objectives\n",
        "- concatenate data with pandas\n",
        "- merge data with pandas\n",
        "-  understand tidy data formatting\n",
        "-  melt and pivot data with pandas\n",
        "\n",
        "Links\n",
        "- [Pandas Cheat Sheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)\n",
        "- [Tidy Data](https://en.wikipedia.org/wiki/Tidy_data)\n",
        "  - Combine Data Sets: Standard Joins\n",
        "  - Tidy Data\n",
        "  - Reshaping Data\n",
        "- Python Data Science Handbook\n",
        "  - [Chapter 3.6](https://jakevdp.github.io/PythonDataScienceHandbook/03.06-concat-and-append.html), Combining Datasets: Concat and Append\n",
        "  - [Chapter 3.7](https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html), Combining Datasets: Merge and Join\n",
        "  - [Chapter 3.8](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html), Aggregation and Grouping\n",
        "  - [Chapter 3.9](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html), Pivot Tables\n",
        "  \n",
        "Reference\n",
        "- Pandas Documentation: [Reshaping and Pivot Tables](https://pandas.pydata.org/pandas-docs/stable/reshaping.html)\n",
        "- Modern Pandas, Part 5: [Tidy Data](https://tomaugspurger.github.io/modern-5-tidy.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MsWLLW4Xg_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfr4_Ya0XkLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar --gunzip --extract --verbose --file=instacart_online_grocery_shopping_2017_05_01.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQf11LsjVgdA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4YyGPNdXrT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd instacart_2017_05_01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b26wmLUiXtlM",
        "colab_type": "code",
        "outputId": "dc958937-2b1b-4b02-bd6e-5af974714b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!ls -lh *.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 502 staff 2.6K May  2  2017 aisles.csv\n",
            "-rw-r--r-- 1 502 staff  270 May  2  2017 departments.csv\n",
            "-rw-r--r-- 1 502 staff 551M May  2  2017 order_products__prior.csv\n",
            "-rw-r--r-- 1 502 staff  24M May  2  2017 order_products__train.csv\n",
            "-rw-r--r-- 1 502 staff 104M May  2  2017 orders.csv\n",
            "-rw-r--r-- 1 502 staff 2.1M May  2  2017 products.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kAMtvSQWPUcj"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "## Join Data Practice\n",
        "\n",
        "These are the top 10 most frequently ordered products. How many times was each ordered? \n",
        "\n",
        "1. Banana\n",
        "2. Bag of Organic Bananas\n",
        "3. Organic Strawberries\n",
        "4. Organic Baby Spinach \n",
        "5. Organic Hass Avocado\n",
        "6. Organic Avocado\n",
        "7. Large Lemon \n",
        "8. Strawberries\n",
        "9. Limes \n",
        "10. Organic Whole Milk\n",
        "\n",
        "First, write down which columns you need and which dataframes have them.\n",
        "\n",
        "Next, merge these into a single dataframe.\n",
        "\n",
        "Then, use pandas functions from the previous lesson to get the counts of the top 10 most frequently ordered products."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvE0EVHgXMFO",
        "colab_type": "code",
        "outputId": "be90fcd9-7a0e-439e-844c-a04b08187faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "##### YOUR CODE HERE #####\n",
        "import pandas as pd\n",
        "\n",
        "!wget https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "%cd instacart_2017_05_01\n",
        "\n",
        "print('\\n')\n",
        "# First, write down which columns you need and which dataframes have them.\n",
        "'''\n",
        "To calculate how many times was each ordered, one will need \n",
        "1) Total # of a) Organic and b) Conventional of the item was ordered, if applicable\n",
        "By cross-checking through the:\n",
        "2) Orders (order_products__prior.csv) and their corresponding\n",
        "  a) Ordered Products (order_products__train.csv)\n",
        "\n",
        " A. COLUMNS NEEDED:\n",
        "    1) product_name in  \n",
        "       a) products.csv # DATAFRAME 1\n",
        "    \n",
        "    2) product_id   &  \n",
        "    3) order_id     or/&\n",
        "    4) order_number in   \n",
        "       a) orders.csv   # DATAFRAME 2\n",
        "'''\n",
        "\n",
        "products_df = pd.read_csv('products.csv', index_col =\"product_name\") #*\n",
        "\n",
        "banana_Row = products_df.loc['Banana']\n",
        "print(banana_Row)  # RTNS THESE ROWS: \"product_id\" = 24852, \"aisle_id\" = 24, \"department_id\" = 4\n",
        "\n",
        "'''\n",
        "products_df.columns\n",
        "products_df.index.value_counts()\n",
        "products_df.head(99999)\n",
        "\n",
        "*\n",
        "A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure. Indexes are used to quickly locate data without having to search every row in a database table every time a database table is accessed. Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access of ordered records.\n",
        "\n",
        "An index is a copy of selected columns of data from a table that can be searched very efficiently that also includes a low-level disk block address or direct link to the complete row of data it was copied from. \n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-10 20:42:38--  https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.97.197\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.97.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 205548478 (196M) [application/x-gzip]\n",
            "Saving to: ‘instacart_online_grocery_shopping_2017_05_01.tar.gz’\n",
            "\n",
            "instacart_online_gr 100%[===================>] 196.03M  27.8MB/s    in 7.6s    \n",
            "\n",
            "2019-11-10 20:42:46 (25.8 MB/s) - ‘instacart_online_grocery_shopping_2017_05_01.tar.gz’ saved [205548478/205548478]\n",
            "\n",
            "instacart_2017_05_01/\n",
            "instacart_2017_05_01/._aisles.csv\n",
            "instacart_2017_05_01/aisles.csv\n",
            "instacart_2017_05_01/._departments.csv\n",
            "instacart_2017_05_01/departments.csv\n",
            "instacart_2017_05_01/._order_products__prior.csv\n",
            "instacart_2017_05_01/order_products__prior.csv\n",
            "instacart_2017_05_01/._order_products__train.csv\n",
            "instacart_2017_05_01/order_products__train.csv\n",
            "instacart_2017_05_01/._orders.csv\n",
            "instacart_2017_05_01/orders.csv\n",
            "instacart_2017_05_01/._products.csv\n",
            "instacart_2017_05_01/products.csv\n",
            "/content/instacart_2017_05_01\n",
            "\n",
            "\n",
            "product_id       24852\n",
            "aisle_id            24\n",
            "department_id        4\n",
            "Name: Banana, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nproducts_df.columns\\nproducts_df.index.value_counts()\\nproducts_df.head(99999)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQSyLs5ZRg2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "41fd8c38-9492-4e3d-c7ed-8b8ae89a9029"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "orders_df = pd.read_csv('orders.csv')\n",
        "orders_df.columns  # gona want 'order_number' or 'order id' columns\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b81da616934b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0morders_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'orders.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0morders_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m  \u001b[0;31m# gona want 'order_number' or 'order id' columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'orders.csv' does not exist: b'orders.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljPJpJ7_XIrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "!wget https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "%cd instacart_2017_05_01\n",
        "'''\n",
        "\n",
        "order_products_df= pd.read_csv('order_products__train.csv')\n",
        "order_products_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bwls8jHdjMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next, merge these into a single dataframe\n",
        "import pandas as pd\n",
        "\n",
        "!wget https://s3.amazonaws.com/instacart-datasets/instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "!tar --gunzip --extract --verbose --file=instacart_online_grocery_shopping_2017_05_01.tar.gz\n",
        "%cd instacart_2017_05_01\n",
        "\n",
        "products_df = pd.read_csv('products.csv')\n",
        "order_products_df =pd.read_csv('order_products__prior.csv')\n",
        "\n",
        "# The 'on' parameter indicates a specific column that is contained in both dataframes. We use it to look up and copy information from the two df's into a combined df.\n",
        "merged_prodsAndorders_df = pd.merge(products_df, order_products_df, on='product_id', how= 'inner' ) \n",
        "\n",
        "# The 'how' parameter indicates what the portion of the selected dataframes to keep after the merge takes place.\n",
        "merged_prodsAndorders_df  # call\n",
        "\n",
        "#order_products_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH49AB-YnfTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then, use pandas functions from the previous lesson to get the counts of the top 10 most frequently ordered products.\n",
        "\n",
        "prod_list=['Banana',\n",
        "'Bag of Organic Bananas',\n",
        "'Organic Strawberries',\n",
        "'Organic Baby Spinach',\n",
        "'Organic Hass Avocado',\n",
        "'Organic Avocado',\n",
        "'Large Lemon',\n",
        "'Strawberries',\n",
        "'Limes',\n",
        "'Organic Whole Milk]\n",
        "\n",
        "def counts_top_10(merged_prodsAndorders_df, prod_list):\n",
        "  for i in prod_list:\n",
        "    # if has Org option:\n",
        "        # \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsiWi4DuXPLP",
        "colab_type": "text"
      },
      "source": [
        "## Reshape Data Section\n",
        "\n",
        "- Replicate the lesson code\n",
        "- Complete the code cells we skipped near the beginning of the notebook\n",
        "- Table 2 --> Tidy\n",
        "- Tidy --> Table 2\n",
        "- Load seaborn's `flights` dataset by running the cell below. Then create a pivot table showing the number of passengers by month and year. Use year for the index and month for the columns. You've done it right if you get 112 passengers for January 1949 and 432 passengers for December 1960."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgxulJQq0uLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flights = sns.load_dataset('flights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qKc88WI0up-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### YOUR CODE HERE #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnOuqL9K0dqh",
        "colab_type": "text"
      },
      "source": [
        "## Join Data Stretch Challenge\n",
        "\n",
        "The [Instacart blog post](https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2) has a visualization of \"**Popular products** purchased earliest in the day (green) and latest in the day (red).\" \n",
        "\n",
        "The post says,\n",
        "\n",
        "> \"We can also see the time of day that users purchase specific products.\n",
        "\n",
        "> Healthier snacks and staples tend to be purchased earlier in the day, whereas ice cream (especially Half Baked and The Tonight Dough) are far more popular when customers are ordering in the evening.\n",
        "\n",
        "> **In fact, of the top 25 latest ordered products, the first 24 are ice cream! The last one, of course, is a frozen pizza.**\"\n",
        "\n",
        "Your challenge is to reproduce the list of the top 25 latest ordered popular products.\n",
        "\n",
        "We'll define \"popular products\" as products with more than 2,900 orders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-QNMrVkYap4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### YOUR CODE HERE #####"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij8S60q0YXxo",
        "colab_type": "text"
      },
      "source": [
        "## Reshape Data Stretch Challenge\n",
        "\n",
        "_Try whatever sounds most interesting to you!_\n",
        "\n",
        "- Replicate more of Instacart's visualization showing \"Hour of Day Ordered\" vs \"Percent of Orders by Product\"\n",
        "- Replicate parts of the other visualization from [Instacart's blog post](https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2), showing \"Number of Purchases\" vs \"Percent Reorder Purchases\"\n",
        "- Get the most recent order for each user in Instacart's dataset. This is a useful baseline when [predicting a user's next order](https://www.kaggle.com/c/instacart-market-basket-analysis)\n",
        "- Replicate parts of the blog post linked at the top of this notebook: [Modern Pandas, Part 5: Tidy Data](https://tomaugspurger.github.io/modern-5-tidy.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d6IA2R0YXFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### YOUR CODE HERE #####"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}